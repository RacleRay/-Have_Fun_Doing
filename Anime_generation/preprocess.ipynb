{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import i2v\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "from imageio import imread\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('characters/*.jpg')\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征提取工具\n",
    "# https://github.com/rezoo/illustration2vec: \n",
    "#   estimating a set of tags and extracting semantic feature vectors from given illustrations.\n",
    "# Requirements:\n",
    "#   pip install chainer Pillow scikit-image\n",
    "illust2vec = i2v.make_i2v_with_chainer('illust2vec_tag_ver200.caffemodel', 'tag_list.json')\n",
    "\n",
    "# 头像截取工具\n",
    "# https://github.com/nagadomi/lbpcascade_animeface：\n",
    "    #   A Face detector for anime/manga using OpenCV\n",
    "cascade = cv2.CascadeClassifier('lbpcascade_animeface.xml')\n",
    "\n",
    "OUTPUT_DIR = 'faces/'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.mkdir(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 头像截取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "for x in tqdm(range(len(images))):\n",
    "    img_path = images[x]\n",
    "    image = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "    faces = cascade.detectMultiScale(gray,\n",
    "                                     scaleFactor=1.1,\n",
    "                                     minNeighbors=5,\n",
    "                                     minSize=(64, 64))\n",
    "    \n",
    "    for i, (x, y, w, h) in enumerate(faces):\n",
    "        cx = x + w // 2\n",
    "        cy = y + h // 2\n",
    "        # 放大选择区域，左上和右下\n",
    "        x0 = cx - int(0.75 * w)\n",
    "        x1 = cx + int(0.75 * w)\n",
    "        y0 = cy - int(0.75 * h)\n",
    "        y1 = cy + int(0.75 * h)\n",
    "        # 越界判断\n",
    "        if x0 < 0:\n",
    "            x0 = 0\n",
    "        if y0 < 0:\n",
    "            y0 = 0\n",
    "        if x1 >= image.shape[1]:\n",
    "            x1 = image.shape[1] - 1\n",
    "        if y1 >= image.shape[0]:\n",
    "            y1 = image.shape[0] - 1\n",
    "        # 放大后的高度宽度\n",
    "        w = x1 - x0\n",
    "        h = y1 - y0\n",
    "        # 修正为正方形，取中间区域正方形\n",
    "        if w > h:\n",
    "            x0 = x0 + w // 2 - h // 2\n",
    "            x1 = x1 - w // 2 + h // 2\n",
    "            w = h\n",
    "        else:\n",
    "            y0 = y0 + h // 2 - w // 2\n",
    "            y1 = y1 - h // 2 + w // 2\n",
    "            h = w\n",
    "\n",
    "        face = image[y0: y0 + h, x0: x0 + w, :]\n",
    "        face = cv2.resize(face, (128, 128))\n",
    "        cv2.imwrite(os.path.join(OUTPUT_DIR, '%d.jpg' % num), face)\n",
    "        num += 1\n",
    "\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw = open('face_tags.txt', 'w')\n",
    "tags = [\n",
    "    'blonde hair', 'brown hair', 'black hair', 'blue hair', 'pink hair',\n",
    "    'purple hair', 'green hair', 'red hair', 'silver hair', 'white hair',\n",
    "    'orange hair', 'aqua hair', 'grey hair', 'long hair', 'short hair',\n",
    "    'twintails', 'drill hair', 'ponytail', 'blue eyes', 'red eyes',\n",
    "    'brown eyes', 'green eyes', 'purple eyes', 'yellow eyes', 'pink eyes',\n",
    "    'aqua eyes', 'black eyes', 'orange eyes', 'blush', 'smile', 'open mouth',\n",
    "    'hat', 'ribbon', 'glasses'\n",
    "]\n",
    "fw.write('id,' + ','.join(tags) + '\\n')\n",
    "\n",
    "images = glob.glob(os.path.join(OUTPUT_DIR, '*.jpg'))\n",
    "for x in tqdm(range(len(images))):\n",
    "    img_path = images[x]\n",
    "    image = imread(img_path)\n",
    "    result = illust2vec.estimate_specific_tags([image], tags)[0]\n",
    "\n",
    "    # 头发颜色取一种\n",
    "    hair_colors = [[h, result[h]] for h in tags[0:13]]\n",
    "    hair_colors.sort(key=lambda x: x[1], reverse=True)\n",
    "    for h in tags[0:13]:\n",
    "        if h == hair_colors[0][0]:\n",
    "            result[h] = 1\n",
    "        else:\n",
    "            result[h] = 0\n",
    "\n",
    "    # 取一种\n",
    "    hair_styles = [[h, result[h]] for h in tags[13:18]]\n",
    "    hair_styles.sort(key=lambda x: x[1], reverse=True)\n",
    "    for h in tags[13:18]:\n",
    "        if h == hair_styles[0][0]:\n",
    "            result[h] = 1\n",
    "        else:\n",
    "            result[h] = 0\n",
    "\n",
    "    eye_colors = [[h, result[h]] for h in tags[18:28]]\n",
    "    eye_colors.sort(key=lambda x: x[1], reverse=True)\n",
    "    for h in tags[18:28]:\n",
    "        if h == eye_colors[0][0]:\n",
    "            result[h] = 1\n",
    "        else:\n",
    "            result[h] = 0\n",
    "\n",
    "    # tags[28:]属性，判断是否超过阈值\n",
    "    for h in tags[28:]:\n",
    "        if result[h] > 0.25:\n",
    "            result[h] = 1\n",
    "        else:\n",
    "            result[h] = 0\n",
    "\n",
    "    fw.write(img_path + ',' + ','.join([str(result[t]) for t in tags]) + '\\n')\n",
    "\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征向量提取--可视化（本例中）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征向量提取，注意使用了不同的caffemodel\n",
    "illust2vec = i2v.make_i2v_with_chainer(\"illust2vec_ver200.caffemodel\")\n",
    "img_all = []\n",
    "vec_all = []\n",
    "\n",
    "for x in tqdm(range(len(images))):\n",
    "    img_path = images[x]\n",
    "    image = imread(img_path)\n",
    "    vector = illust2vec.extract_feature([image])[0]\n",
    "    img_all.append(image / 255.)\n",
    "    vec_all.append(vector)\n",
    "\n",
    "img_all = np.array(img_all)\n",
    "vec_all = np.array(vec_all)\n",
    "\n",
    "with open('img_vector.pkl', 'wb') as fw:\n",
    "    pickle.dump({'img': img_all, 'vec': vec_all}, fw, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('img_vector.pkl', 'rb') as fr:\n",
    "    data = pickle.load(fr)\n",
    "    img_all = data['img']\n",
    "    vec_all = data['vec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from imageio import imsave\n",
    "\n",
    "\n",
    "data_index = np.arange(img_all.shape[0])\n",
    "np.random.shuffle(data_index)\n",
    "data_index = data_index[:2000]\n",
    "\n",
    "tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)\n",
    "two_d_vectors = tsne.fit_transform(vec_all[data_index, :])\n",
    "puzzles = np.ones((6400, 6400, 3))\n",
    "xmin = np.min(two_d_vectors[:, 0])\n",
    "xmax = np.max(two_d_vectors[:, 0])\n",
    "ymin = np.min(two_d_vectors[:, 1])\n",
    "ymax = np.max(two_d_vectors[:, 1])\n",
    "\n",
    "for i, vector in enumerate(two_d_vectors):\n",
    "    x, y = two_d_vectors[i, :]\n",
    "    x = int((x - xmin) / (xmax - xmin) * (6400 - 128) + 64)\n",
    "    y = int((y - ymin) / (ymax - ymin) * (6400 - 128) + 64)\n",
    "    puzzles[y - 64: y + 64, x - 64: x + 64, :] = img_all[data_index[i]]\n",
    "\n",
    "imsave('二次元头像降维可视化.png', puzzles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
