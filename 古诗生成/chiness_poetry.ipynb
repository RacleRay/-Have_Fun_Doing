{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T17:32:06.674610Z",
     "start_time": "2019-10-18T17:32:02.362627Z"
    }
   },
   "outputs": [],
   "source": [
    "# 数据：https://github.com/chinese-poetry/chinese-poetry\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "import json\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from snownlp import SnowNLP  # 简繁体转化功能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T17:32:10.190205Z",
     "start_time": "2019-10-18T17:32:06.796280Z"
    }
   },
   "outputs": [],
   "source": [
    "# 非完整数据，\n",
    "poets = []\n",
    "paths = glob.glob('chinese-poetry/json/poet.*.json')\n",
    "\n",
    "for path in paths:\n",
    "    data = open(path, 'r', encoding='utf-8').read()\n",
    "    data = json.loads(data)\n",
    "    \n",
    "    for item in data:\n",
    "        content = ' '.join(item['paragraphs'])\n",
    "        if len(content) >= 24 and len(content) <= 32:\n",
    "            content = SnowNLP(content)\n",
    "            poets.append('[' + content.han + ']')\n",
    "            \n",
    "poets.sort(key=lambda x: len(x))\n",
    "print('共%d首诗' % len(poets), poets[0], poets[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### id to word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T17:32:10.672915Z",
     "start_time": "2019-10-18T17:32:10.497384Z"
    }
   },
   "outputs": [],
   "source": [
    "chars = []\n",
    "for item in poets:\n",
    "    chars += [c for c in item]\n",
    "\n",
    "print('共%d个字' % len(chars))\n",
    "\n",
    "chars = sorted(Counter(chars).items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print('共%d个不同的字' % len(chars))\n",
    "print(chars[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T17:32:11.028977Z",
     "start_time": "2019-10-18T17:32:11.019987Z"
    }
   },
   "outputs": [],
   "source": [
    "chars = [c[0] for c in chars]\n",
    "\n",
    "char2id = {c: i + 1 for i, c in enumerate(chars)}\n",
    "id2char = {i + 1: c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T17:32:11.595449Z",
     "start_time": "2019-10-18T17:32:11.369053Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "X_data = []\n",
    "Y_data = []\n",
    "\n",
    "for b in range(len(poets) // batch_size):\n",
    "    start = b * batch_size\n",
    "    end = b * batch_size + batch_size\n",
    "    \n",
    "    batch = [[char2id[c] for c in poets[i]] for i in range(start, end)]\n",
    "    maxlen = max(map(len, batch))\n",
    "    \n",
    "    X_batch = np.full((batch_size, maxlen - 1), 0, np.int32)\n",
    "    Y_batch = np.full((batch_size, maxlen - 1), 0, np.int32)\n",
    "    \n",
    "    # X与Y，错开一位\n",
    "    for i in range(batch_size):\n",
    "        X_batch[i, :len(batch[i]) - 1] = batch[i][:-1]\n",
    "        Y_batch[i, :len(batch[i]) - 1] = batch[i][1:]\n",
    "    \n",
    "    X_data.append(X_batch)\n",
    "    Y_data.append(Y_batch)\n",
    "    \n",
    "print(len(X_data), len(Y_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T17:32:13.221114Z",
     "start_time": "2019-10-18T17:32:13.181209Z"
    }
   },
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "num_layer = 2\n",
    "embedding_size = 256\n",
    "\n",
    "X = tf.placeholder(tf.int32, [batch_size, None])\n",
    "Y = tf.placeholder(tf.int32, [batch_size, None])\n",
    "learning_rate = tf.Variable(0.0, trainable=False)  # 后面会赋值\n",
    "\n",
    "# len(char2id) + 1: padding\n",
    "embeddings = tf.Variable(tf.random_uniform([len(char2id) + 1, embedding_size], -1.0, 1.0))\n",
    "embedded = tf.nn.embedding_lookup(embeddings, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T17:32:14.914572Z",
     "start_time": "2019-10-18T17:32:14.869694Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cell = tf.nn.rnn_cell.MultiRNNCell(\n",
    "            [tf.nn.rnn_cell.BasicLSTMCell(hidden_size, state_is_tuple=True) for i in range(num_layer)],\n",
    "            state_is_tuple=True\n",
    "            )\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T17:32:16.858383Z",
     "start_time": "2019-10-18T17:32:16.566157Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# outputs: [batch_size, max_time, hidden_size]\n",
    "# last_states: (([batch_size, hidden_size], [batch_size, hidden_size]), \n",
    "#                    ([batch_size, hidden_size], [batch_size, hidden_size]))\n",
    "#  两层lstm，分别由C 和 H，维度为[batch_size, hidden_size]\n",
    "outputs, last_states = tf.nn.dynamic_rnn(cell, embedded, initial_state=initial_state)\n",
    "\n",
    "outputs = tf.reshape(outputs, [-1, hidden_size])\n",
    "logits = tf.layers.dense(outputs, units=len(char2id) + 1)\n",
    "# 转换到每一步的输出结果\n",
    "logits = tf.reshape(logits, [batch_size, -1, len(char2id) + 1])\n",
    "probs = tf.nn.softmax(logits, name=\"prob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T17:32:19.966068Z",
     "start_time": "2019-10-18T17:32:18.501981Z"
    }
   },
   "outputs": [],
   "source": [
    "# tf.ones_like(Y, dtype=tf.float32): 每个结果的权重，设为一致\n",
    "loss = tf.reduce_mean(tf.contrib.seq2seq.sequence_loss(logits, Y, tf.ones_like(Y, dtype=tf.float32)))\n",
    "\n",
    "# 梯度截断\n",
    "params = tf.trainable_variables()\n",
    "grads, _ = tf.clip_by_global_norm(tf.gradients(loss, params), 5)\n",
    "optimizer = tf.train.AdadeltaOptimizer(learning_rate).apply_gradients(zip(grads, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T17:55:38.389042Z",
     "start_time": "2019-10-18T17:32:21.605683Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(60):\n",
    "    sess.run(tf.assign(learning_rate, 0.002 * (0.97 ** epoch)))\n",
    "    \n",
    "    data_index = np.arange(len(X_data))\n",
    "    np.random.shuffle(data_index)\n",
    "    X_data = [X_data[i] for i in data_index]\n",
    "    Y_data = [Y_data[i] for i in data_index]\n",
    "    \n",
    "    losses = []\n",
    "    for i in tqdm(range(len(X_data))):\n",
    "        ls_,  _ = sess.run([loss, optimizer], feed_dict={X: X_data[i], Y: Y_data[i]})\n",
    "        losses.append(ls_)\n",
    "    \n",
    "    print('Epoch %d Loss %.5f' % (epoch, np.mean(losses)))\n",
    "\n",
    "# 保存模型和词表\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess, './poet_generation_tensorflow')\n",
    "\n",
    "import pickle\n",
    "with open('dictionary.pkl', 'wb') as fw:\n",
    "    pickle.dump([char2id, id2char], fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T17:07:13.752724Z",
     "start_time": "2019-10-18T17:07:13.749726Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(sess.graph_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T02:54:55.328425Z",
     "start_time": "2019-10-19T02:54:53.145243Z"
    }
   },
   "outputs": [],
   "source": [
    "# 同一个文件中，请restart\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T02:54:56.141225Z",
     "start_time": "2019-10-19T02:54:56.133246Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('dictionary.pkl', 'rb') as f:\n",
    "    [char2id, id2char] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T02:55:37.877631Z",
     "start_time": "2019-10-19T02:55:37.593391Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-3-7e34460d7cd0>:12: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-3-7e34460d7cd0>:13: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-3-7e34460d7cd0>:19: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From <ipython-input-3-7e34460d7cd0>:22: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "hidden_size = 256\n",
    "num_layer = 2\n",
    "embedding_size = 256\n",
    "\n",
    "# 定义图结构，再加载参数，预测使用到last_states，get_tensor_by_name不能直接取到\n",
    "X = tf.placeholder(tf.int32, [batch_size, None])\n",
    "Y = tf.placeholder(tf.int32, [batch_size, None])\n",
    "learning_rate = tf.Variable(0.0, trainable=False)\n",
    "\n",
    "cell = tf.nn.rnn_cell.MultiRNNCell(\n",
    "    [tf.nn.rnn_cell.BasicLSTMCell(hidden_size, state_is_tuple=True) for i in range(num_layer)], \n",
    "    state_is_tuple=True)\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "embeddings = tf.Variable(tf.random_uniform([len(char2id) + 1, embedding_size], -1.0, 1.0))\n",
    "embedded = tf.nn.embedding_lookup(embeddings, X)\n",
    "\n",
    "outputs, last_states = tf.nn.dynamic_rnn(cell, embedded, initial_state=initial_state)\n",
    "\n",
    "outputs = tf.reshape(outputs, [-1, hidden_size])\n",
    "logits = tf.layers.dense(outputs, units=len(char2id) + 1)\n",
    "# 转换到每一步的输出结果\n",
    "logits = tf.reshape(logits, [batch_size, -1, len(char2id) + 1])\n",
    "probs = tf.nn.softmax(logits, name=\"prob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T02:55:41.511087Z",
     "start_time": "2019-10-19T02:55:40.232337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./poet_generation_tensorflow\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, tf.train.latest_checkpoint('./'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T17:25:10.063927Z",
     "start_time": "2019-10-18T17:25:10.059933Z"
    }
   },
   "outputs": [],
   "source": [
    "# get_tensor_by_name\n",
    "# inputs = tf.get_default_graph().get_tensor_by_name('Placeholder:0')\n",
    "# prob_ = tf.get_default_graph().get_tensor_by_name('prob:0')\n",
    "# last_states取不到"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 自动生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T02:56:35.831909Z",
     "start_time": "2019-10-19T02:56:35.704251Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def generate():\n",
    "    states_ = sess.run(initial_state)\n",
    "\n",
    "    gen = ''\n",
    "    c = '['\n",
    "    while c != ']':\n",
    "        gen += c\n",
    "        x = np.zeros((batch_size, 1))\n",
    "        x[:, 0] = char2id[c]\n",
    "        probs_, states_ = sess.run([probs, last_states],\n",
    "                                   feed_dict={\n",
    "                                       X: x,\n",
    "                                       initial_state: states_\n",
    "                                   })\n",
    "        probs_ = np.squeeze(probs_)\n",
    "        # 相当于在一条直线上，累计划分每个预测概率的长度，产生随机数，看落在哪一个区段\n",
    "        pos = int(\n",
    "            np.searchsorted(np.cumsum(probs_),\n",
    "                            np.random.rand() * np.sum(probs_)))\n",
    "\n",
    "        c = id2char[pos]\n",
    "        \n",
    "    return gen[1: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T02:56:35.831909Z",
     "start_time": "2019-10-19T02:56:35.704251Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "西北空教已十秋，东皇犹未识新秋。黄头可得归斯臭，更跃齐眉疾不忧。\n"
     ]
    }
   ],
   "source": [
    "print(generate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 藏头"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T02:57:00.611210Z",
     "start_time": "2019-10-19T02:57:00.604229Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_with_head(head):\n",
    "    states_ = sess.run(initial_state)\n",
    "    \n",
    "    gen = ''\n",
    "    c = '['\n",
    "    i = 0\n",
    "    while c != ']':\n",
    "        gen += c\n",
    "        x = np.zeros((batch_size, 1))\n",
    "        x[:, 0] = char2id[c]\n",
    "        probs_, states_ = sess.run([probs, last_states], feed_dict={X: x, initial_state: states_})\n",
    "        probs_ = np.squeeze(probs_)\n",
    "        pos = int(np.searchsorted(np.cumsum(probs_), np.random.rand() * np.sum(probs_)))\n",
    "        \n",
    "        # 下一个c，在每一句开头处，替换掉预测词\n",
    "        if (c == '[' or c == '。' or c == '，') and i < len(head):\n",
    "            c = head[i]\n",
    "            i += 1\n",
    "        else:\n",
    "            c = id2char[pos]\n",
    "    \n",
    "    return gen[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T02:59:16.565839Z",
     "start_time": "2019-10-19T02:59:16.204082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'罗浮翠幄古今红，小槛孤根两字红。黑白芙蓉素花入，请君不解继高风。早迁高士佩骊龙，安得天为唱道公。'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_with_head('罗小黑请早安')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-kernel",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
